Une ligne de commande est une ou plusieurs commandes separees par des pipes avec les options de chaque commandes, les redirections (< > << >>).
On balaye une premiere fois la ligne de commande pour chercher des potentiels "||", les "&&" qui renveront un message d'erreur. Si la ligne de commande commence ou termine par un | on renvoie aussi un message d'erreur.
On split la ligne de commande avec | comme separateur
On traite chaque str independamment
-On isole les redirections (Les chevrons sont suivis soit par des espaces soit directement par le fichier/limiter de redirection)
-Il ne reste que la commande et ses options, la commande sera le premier terme trouve dans le reste
-On creer un tableau de char* avec ce reste pour l'envoyer a execve dans l'ordre dans lequel les options sont tapees

Ensuite, on check si la commande est un built-in, sinon on l'envoie a execve


Gestion des pipes:
Le nb de cellule du tableau de notre premier split -1 est le nombre de pipe a creer
[pipex_bonus]

Renvoyer le prompt pour accepter une nouvelle ligne de commande


Readline
On appelle la fonction readline dans une boucle (while(1)?)
On recupere le pwd d


{Parsing independant de toute la data du runtime
Association d'IDs aux tokens, une fois la tokenization faite, uniquement se servir des IDs
Parsing sans "regarder trop loin", on ne regarde qu'un nombre limite de tokens a la fois, et un token n'est regarde qu'une seule fois} -> There are several quirks in the shell language that prevent us from strictly following these principles. And "real" parsers violate them: for example, most parsers re-examine the contents of tokens for C-like string and number literals (e.g. Python's parser).

But I claim that they're good aspirations. They improve the quality of your parsing code, and can improve the design of your language.

DELIMITER= Whitespaces, $, <, >, |, "", ''

Types de tokens: 
- Cmd
- Arg
- Pipe
- Redir in
- Redir out



-Caractere speciaux autres que requis par le sujet : Renvoie une erreur

si un mot commence par un nombre, on raise un flag -Number -> le token peut etre un mot ou un fd pour une redirection




1er split avec espaces en respectant les quotes
si la quote en str[0] d'une chaine resultante d'un split apparait un nombre impair de fois, on renvoie une erreur (UNCLOSED QUOTES)

e.g.: cat "out3.txt">"out.txt" == split[0] = "cat"
									split[1] = "\"out3.txt\">\"out.txt\""
on trim les quotes puis on reparse chaque chaine pour creer les tokens en fonctions des conditions donnees dans la fonction ci-dessous
on ajoute ces tokens a une liste chainee


void parse(char *str) -> str a ete split et on n'appelle cette fonction que si la chaine n'est pas entre quotes
{
	int nb = 0;
	int word = 0;
	int redir = 0;
	int pipe = 0;


	while (str[i++])
	{

		if is_digit(str[i])
		{	
			nb = 1;
			word = 1;
		}
		if (str[i] == < || str[i] == >)
		{
			if (nb=1)
			{
				nb = 0;
				word = 0;
				redir = 1;
			}
		}
	}
/***********************************************************************************************/
Normalisation des regles 

QUOTES: -> Ce que l'on recoit entre quotes sera toujours traite comme un char *
Entre quotes on peut avoir: -Un nom de fichier que l'on determine par rapport a la place des chevrons
							-Un nom de commande que l'on peut aussi determiner
							-Une ET SEULEMENT une option de la commande associee a ce pipe

SEPARATEURS:
{
	speciaux:[<, >, |, <<, >>]
	naturels:[espaces]
}

speciaux > si on les rencontre, on creer un nouveau token mais il faut verifier:
Pipe: 	-On check derriere pour etre sur que ce ne soit pas || sinon erreur
		-On check si ce n'est pas le premier ou le dernier caractere de la chaine
Chevrons:	-On check si avant le chevron il y a un chiffre
			Si oui, on recule jusqu'au premier (whitespace ou pipe) -> ceci est le fd
			-On check derriere si il y a un autre chevron identique pour transformer le in/out en heredoc/append

 --> On devrait donc trim tous les whitespace situes autour de chevrons dans la ligne recuperee par readline


 char *trim_whitespace(char *str)
 {

 	int i;
 	int j;

 	i = 0;
 	j = 0;

 	while (str[i] != 0)
 	{
 		if(str[i] == '< || str[i] == '>')
 		{

 		}
 	}
 }

 ----------------------------------------------------------------------------

 05/05 Minishell

Lexer -> le gros est fait, reste a gerer les frees de liste chainees etc

Asuivre : Expand -> Ce soir
			Parsing (Gestion d'erreurs etc).
			
Expand -> On expand apres avoir creer les tokens, mais avant de refine les tokens word. Cependant, on attribuera les tokens file avant de refine -> les tokens words seront des commandes ou des arguments
On expand le meme type, en pensant a conserver la valeur d'avant l'expand (pour la gestion d'erreurs).
On substitue chaque expand trouve dans un maillon par leur valeur, on split cette valeur (split2) et on creer autant de nouveau maillon de notre liste chainee qu'il y a de cellules de split en attribuant le meme type de token a chaque maillon
Et seulement apres, on refine les commandes et les arguments

Fonctions:
Refaire le refine token -> deux passages differents -> Sacha + chercher la variable dans l'env -> On envoie un array (Si on essaie d'expand un truc qui n'existe pas, renvoie une chaine vide)
Expand -> Realloc (), Manipulation des pointeurs de la liste chainee, substitution -> Maxime 
 
PAS D'EXPAND SI ON EST SUR UN LIMITER DE HEREDOC 

1 -> On split +creer les tokens (A ce momemt la, seuls les operateurs sont definis)
2 -> On refine une premiere fois (On peut determiner les FILES, LIMITER, FD)
3 -> On expand
4 -> On refine les commandes/arguments